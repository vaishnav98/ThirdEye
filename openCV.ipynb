{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](img/asdfghjkl.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPEN CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing open cv and numpy in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the function cv2.imread() to read an image. The image should be in the working directory or a full path of image should be given.\n",
    "\n",
    "Second argument is a flag which specifies the way image should be read.\n",
    "\n",
    "    cv2.IMREAD_COLOR : Loads a color image. Any transparency of image will be neglected. It is the default flag.\n",
    "    cv2.IMREAD_GRAYSCALE : Loads image in grayscale mode\n",
    "    cv2.IMREAD_UNCHANGED : Loads image as such including alpha channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an color image in grayscale\n",
    "img = cv2.imread('C:/Python27/5Stress_post.jpg',0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display an image\n",
    "\n",
    "Use the function cv2.imshow() to display an image in a window. The window automatically fits to the image size.\n",
    "\n",
    "First argument is a window name which is a string. second argument is our image. You can create as many windows as you wish, but with different window names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image',img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2.waitKey() is a keyboard binding function. Its argument is the time in milliseconds. The function waits for specified milliseconds for any keyboard event. If you press any key in that time, the program continues. If 0 is passed, it waits indefinitely for a key stroke. It can also be set to detect specific key strokes like, if key a is pressed etc which we will discuss below.\n",
    "\n",
    "cv2.destroyAllWindows() simply destroys all the windows we created. If you want to destroy any specific window, use the function cv2.destroyWindow() where you pass the exact window name as the argument."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write an image\n",
    "\n",
    "Use the function cv2.imwrite() to save an image.\n",
    "\n",
    "First argument is the file name, second argument is the image you want to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('messigray.png',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will save the image in PNG format in the working directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture Video from Camera\n",
    "Often, we have to capture live stream with camera. OpenCV provides a very simple interface to this. Let’s capture a video from the camera (I am using the in-built webcam of my laptop), convert it into grayscale video and display it. Just a simple task to get started.\n",
    "\n",
    "To capture a video, you need to create a VideoCapture object. Its argument can be either the device index or the name of a video file. Device index is just the number to specify which camera. Normally one camera will be connected (as in my case). So I simply pass 0 (or -1). You can select the second camera by passing 1 and so on. After that, you can capture frame-by-frame. But at the end, don’t forget to release the capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Our operations on the frame come here\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #cv2.waitKey(5000)\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(' '):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playing Video from file\n",
    "It is same as capturing from Camera, just change camera index with video file name. Also while displaying the frame, use appropriate time for cv2.waitKey(). If it is too less, video will be very fast and if it is too high, video will be slow (Well, that is how you can display videos in slow motion). 25 milliseconds will be OK in normal cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture('C:/Python27/big.mp4')\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    cv2.imshow('frame',gray)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing Functions in OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing Line\n",
    "To draw a line, you need to pass starting and ending coordinates of line. We will draw a yellow line on a picture from top-left to bottom-right corners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all the above functions, you will see some common arguments as given below:\n",
    "\n",
    "img : The image where you want to draw the shapes\n",
    "\n",
    "color : Color of the shape. for BGR, pass it as a tuple, eg: (255,0,0) for blue. For grayscale, just pass the scalar value.\n",
    "\n",
    "thickness : Thickness of the line or circle etc. If -1 is passed for closed figures like circles, it will fill the shape. default thickness = 1\n",
    "\n",
    "lineType : Type of line, whether 8-connected, anti-aliased line etc. By default, it is 8-connected. cv2.LINE_AA gives anti-aliased line which looks great for curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "# Load an color image\n",
    "img = cv2.imread('C:/Python27/5Stress_post.jpg', cv2.IMREAD_COLOR)\n",
    " \n",
    "#draw a yellow line\n",
    "cv2.line(img, (0,0), (1024,600), (0,255,255),20)\n",
    " \n",
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing Rectangle\n",
    "To draw a rectangle, you need top-left corner and bottom-right corner of rectangle. This time we will draw a green rectangle at the top-right corner of image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "# Load an color image\n",
    "img = cv2.imread('C:/Python27/5Stress_post.jpg', cv2.IMREAD_COLOR)\n",
    " \n",
    "#draw a rectangle\n",
    "cv2.rectangle(img,(0,0),(300,200),(0,255,0),3)\n",
    " \n",
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drawing Circle\n",
    "To draw a circle, you need its center coordinates and radius. We will draw a circle inside the rectangle drawn above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "# Load an color image\n",
    "img = cv2.imread('C:/Python27/5Stress_post.jpg', cv2.IMREAD_COLOR)\n",
    " \n",
    "#draw a circle\n",
    "cv2.circle(img,(447,63), 63, (0,0,0), -1)\n",
    " \n",
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Tracking\n",
    "Now we know how to convert BGR image to HSV, we can use this to extract a colored object. In HSV, it is more easier to represent a color than RGB color-space. In our application, we will try to extract a blue colored object. So here is the method:\n",
    "\n",
    "    Take each frame of the video\n",
    "    \n",
    "    Convert from BGR to HSV color-space\n",
    "    \n",
    "    We threshold the HSV image for a range of blue color\n",
    "    \n",
    "    Now extract the blue object alone, we can do whatever on that image we want.\n",
    "Below is the code which are commented in detail :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(1):\n",
    "\n",
    "    # Take each frame\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    # Convert BGR to HSV\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # define range of blue color in HSV\n",
    "    lower_blue = np.array([110,50,50])\n",
    "    upper_blue = np.array([130,255,255])\n",
    "\n",
    "    # Threshold the HSV image to get only blue colors\n",
    "    mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(frame,frame, mask= mask)\n",
    "\n",
    "    cv2.imshow('frame',frame)\n",
    "    cv2.imshow('mask',mask)\n",
    "    cv2.imshow('res',res)\n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2  \n",
    "  \n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml') \n",
    "  \n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml') \n",
    "# capture frames from a camer\n",
    "cap = cv2.VideoCapture(0) \n",
    "  \n",
    "# loop runs if capturing has been initialized. \n",
    "while 1:  \n",
    "  \n",
    "    # reads frames from a camera \n",
    "    ret, img = cap.read()  \n",
    "  \n",
    "    # convert to gray scale of each frames \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imshow('gray',gray)\n",
    "  \n",
    "    # Detects faces of different sizes in the input image \n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5) \n",
    "  \n",
    "    for (x,y,w,h) in faces: \n",
    "        # To draw a rectangle in a face  \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,255,0),2)  \n",
    "        roi_gray = gray[y:y+h, x:x+w] \n",
    "        roi_color = img[y:y+h, x:x+w] \n",
    "  \n",
    "        # Detects eyes of different sizes in the input image \n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray)  \n",
    "  \n",
    "        #To draw a rectangle in eyes \n",
    "        for (ex,ey,ew,eh) in eyes: \n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,127,255),2) \n",
    "            \n",
    "    # Display an image in a window \n",
    "    cv2.imshow('img',img) \n",
    "  \n",
    "    # Wait for Esc key to stop \n",
    "    k = cv2.waitKey(30) & 0xff\n",
    "    if k == 27: \n",
    "        break\n",
    "  \n",
    "# Close the window \n",
    "cap.release() \n",
    "  \n",
    "# De-allocate any associated memory usage \n",
    "cv2.destroyAllWindows()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
